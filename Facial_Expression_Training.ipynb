{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=center> Facial Expression Recognition</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Task 1: Import Libraries\n",
    "- Task 2: Plot Sample Images\n",
    "- Task 3: Generate Training and Validation Batches\n",
    "- Task 4: Apply CNN Model\n",
    "- Task 5: Train and Evaluate Model\n",
    "- Task 6: Represent Model as JSON String"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:32:07.896419Z",
     "iopub.status.busy": "2022-01-03T14:32:07.896136Z",
     "iopub.status.idle": "2022-01-03T14:32:13.137869Z",
     "shell.execute_reply": "2022-01-03T14:32:13.137097Z",
     "shell.execute_reply.started": "2022-01-03T14:32:07.896381Z"
    },
    "id": "wvGxjjeV-9Ls"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from tensorflow.keras.applications import resnet\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from tensorflow.keras.applications import resnet_v2\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow import keras\n",
    "\n",
    "from IPython.display import SVG, Image\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Plot Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:32:36.605909Z",
     "iopub.status.busy": "2022-01-03T14:32:36.603993Z",
     "iopub.status.idle": "2022-01-03T14:32:36.969925Z",
     "shell.execute_reply": "2022-01-03T14:32:36.968882Z",
     "shell.execute_reply.started": "2022-01-03T14:32:36.605868Z"
    }
   },
   "outputs": [],
   "source": [
    "emotion_prop5=[]\n",
    "\n",
    "for expression5 in os.listdir(\"Dataset7/train3/\"):\n",
    "    emotion_prop5.append(len(os.listdir(\"Dataset7/train3/\" + expression5)))\n",
    "    print(str(len(os.listdir(\"Dataset7/train3/\" + expression5))) + \" \" + expression5 + \" images\")\n",
    "\n",
    "print(\"emotion_prop4 = \",emotion_prop5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:32:36.971519Z",
     "iopub.status.busy": "2022-01-03T14:32:36.971267Z",
     "iopub.status.idle": "2022-01-03T14:32:37.211261Z",
     "shell.execute_reply": "2022-01-03T14:32:37.210602Z",
     "shell.execute_reply.started": "2022-01-03T14:32:36.971484Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emotions5 = ['happy','surprise','neutral','fear','angry','sad','disgust']\n",
    "palette5 = ['gold','deepskyblue','cornflowerblue','orange','cornflowerblue','lightgreen','lightcoral']\n",
    "plt.figure(figsize=[12,6])\n",
    "plt.bar(x=emotions5, height=emotion_prop5, color=palette5, edgecolor='black')\n",
    "plt.xlabel('Emotion')\n",
    "plt.ylabel('Proportion')\n",
    "plt.title('Emotion Label Proportions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Generate Training and Validation Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:32:37.213857Z",
     "iopub.status.busy": "2022-01-03T14:32:37.212338Z",
     "iopub.status.idle": "2022-01-03T14:32:37.217682Z",
     "shell.execute_reply": "2022-01-03T14:32:37.217033Z",
     "shell.execute_reply.started": "2022-01-03T14:32:37.213815Z"
    }
   },
   "outputs": [],
   "source": [
    "# for resnet50_v2\n",
    "img_size = 224\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:32:37.219489Z",
     "iopub.status.busy": "2022-01-03T14:32:37.219077Z",
     "iopub.status.idle": "2022-01-03T14:32:50.188669Z",
     "shell.execute_reply": "2022-01-03T14:32:50.187778Z",
     "shell.execute_reply.started": "2022-01-03T14:32:37.219450Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_grayscale_then_rgb(image):\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.image.grayscale_to_rgb(image)\n",
    "    return image\n",
    "\n",
    "datagen_train5 = ImageDataGenerator(preprocessing_function=to_grayscale_then_rgb,\n",
    "                                   rescale=1/255, rotation_range=10, brightness_range=[0.2,1.0])\n",
    "train_generator5 = datagen_train5.flow_from_directory(\"Dataset7/train3/\",\n",
    "                                                    target_size=(img_size,img_size),\n",
    "                                                    color_mode=\"rgb\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)\n",
    "\n",
    "datagen_validation5 = ImageDataGenerator(preprocessing_function=to_grayscale_then_rgb,\n",
    "                                        rescale=1/255, rotation_range=10,brightness_range=[0.2,1.0])\n",
    "validation_generator5 = datagen_validation5.flow_from_directory(\"Dataset7/test3/\",\n",
    "                                                    target_size=(img_size,img_size),\n",
    "                                                    color_mode=\"rgb\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Apply CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:32:50.222104Z",
     "iopub.status.busy": "2022-01-03T14:32:50.221859Z",
     "iopub.status.idle": "2022-01-03T14:32:55.053687Z",
     "shell.execute_reply": "2022-01-03T14:32:55.052933Z",
     "shell.execute_reply.started": "2022-01-03T14:32:50.222071Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ahmed sabry\n",
    "resnet50V2_model = resnet_v2.ResNet50V2(include_top=True,\n",
    "                               weights=\"imagenet\",\n",
    "                               input_shape=(img_size,img_size,3),\n",
    "                               classifier_activation=\"softmax\",\n",
    "                               classes=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:33:43.884544Z",
     "iopub.status.busy": "2022-01-03T14:33:43.883834Z",
     "iopub.status.idle": "2022-01-03T14:33:44.283142Z",
     "shell.execute_reply": "2022-01-03T14:33:44.282422Z",
     "shell.execute_reply.started": "2022-01-03T14:33:43.884506Z"
    }
   },
   "outputs": [],
   "source": [
    "### # Initialising the CNN\n",
    "model5 = Sequential()\n",
    "model5.add(resnet50V2_model)\n",
    "# Fully connected layer 1st layer\n",
    "model5.add(Dense(512, kernel_regularizer=regularizers.l2(l=0.01)))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(Activation('relu'))\n",
    "model5.add(Dropout(0.25))\n",
    "# Fully connected layer 2nd layer\n",
    "model5.add(Dense(256, kernel_regularizer=regularizers.l2(l=0.01)))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(Activation('relu'))\n",
    "model5.add(Dropout(0.25))\n",
    "model5.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:33:53.602443Z",
     "iopub.status.busy": "2022-01-03T14:33:53.601605Z",
     "iopub.status.idle": "2022-01-03T14:33:54.007098Z",
     "shell.execute_reply": "2022-01-03T14:33:54.006389Z",
     "shell.execute_reply.started": "2022-01-03T14:33:53.602395Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "model5.compile(optimizer=Adam(lr=0.0001), loss = tfa.losses.SigmoidFocalCrossEntropy(alpha=0.20, gamma=2.0,reduction=tf.keras.losses.Reduction.AUTO), metrics=METRICS)\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:34:00.080825Z",
     "iopub.status.busy": "2022-01-03T14:34:00.080382Z",
     "iopub.status.idle": "2022-01-03T14:34:00.090610Z",
     "shell.execute_reply": "2022-01-03T14:34:00.089528Z",
     "shell.execute_reply.started": "2022-01-03T14:34:00.080781Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epochs5 =10\n",
    "steps_per_epoch5 = train_generator5.n//train_generator5.batch_size\n",
    "validation_steps5 = validation_generator5.n//validation_generator5.batch_size\n",
    "\n",
    "#Reduce learning rate when a metric has stopped improving.\n",
    "reduce_lr5 = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=2, min_lr=0.000001, mode='auto')\n",
    "#save the Keras model or model weights at some frequency.\n",
    "checkpoint5 = ModelCheckpoint(\"model_weights5.h5\", monitor='val_prc',\n",
    "                             save_weights_only=True, mode='max', verbose=1)\n",
    "#Stop training when a monitored metric has stopped improving.\n",
    "early_stopp = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "#Callback\n",
    "callbacks5 = [PlotLossesKerasTF(), checkpoint5, reduce_lr5,early_stopp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:34:08.269361Z",
     "iopub.status.busy": "2022-01-03T14:34:08.268894Z"
    }
   },
   "outputs": [],
   "source": [
    "#Train the model\n",
    "history5 = model5.fit(x = train_generator5,\n",
    "                      steps_per_epoch = steps_per_epoch5,\n",
    "                      epochs = epochs5,\n",
    "                      validation_data = validation_generator5,\n",
    "                      validation_steps = validation_steps5,\n",
    "                      callbacks = callbacks5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Represent Model as JSON String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json5 = model5.to_json()\n",
    "with open(\"./model5.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
